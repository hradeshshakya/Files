{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Frameworks"
      ],
      "metadata": {
        "id": "UaDzzj0T-7wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?**\n",
        " Ans.\n",
        " TensorFlow 2.0 is an updated version of TensorFlow that has been designed with a focus on simple execution, ease of use, and developer's productivity. TensorFlow 2.0 makes the development of data science and machine learning applications even easier.\n",
        "\n",
        " Fundamentally, TF1. x and TF2 use a different set of runtime behaviors around execution (eager in TF2), variables, control flow, tensor shapes, and tensor equality comparisons. To be TF2 compatible, your code must be compatible with the full set of TF2 behaviors.\n",
        "\n",
        "**2. How do you install TensorFlow 2.0?**\n",
        "Ans.\n",
        "To install TensorFlow 2.0, you can use the following steps:\n",
        "Get a Python environment: You can use Anaconda or Miniconda.\n",
        "Install pip for Python: You can upgrade pip to install the TensorFlow 2 package.\n",
        "Create a TensorFlow virtual environment: You can use the following commands:\n",
        "conda create --name tf2.5 python==3.8\n",
        "conda activate tf2.5\n",
        "Install TensorFlow: You can use the following commands:\n",
        "pip install tensorflow for the current stable release\n",
        "pip install tf-nightly for a preview build\n",
        "pip install --upgrade tensorflow-gpu for TensorFlow GPU\n",
        "\n",
        "**3. What is the primary function of the tf.function in TensorFlow 2.0?**\n",
        "Ans.\n",
        "tf. function() can accept Python objects, such as lists, tuples, and dicts, as inputs or outputs, by converting them into tensors or nested structures of tensors. tf. function() bridges the gap between eager execution and graph execution by separating the code into two stages: tracing and running.\n",
        "\n",
        "**4. What is the purpose of the Model class in TensorFlow 2.0?**\n",
        "Ans.\n",
        "Model subclassing with Keras and TensorFlow 2.0\n",
        "Inside of Keras the Model class is the root class used to define a model architecture. Since Keras utilizes object-oriented programming, we can actually subclass the Model class and then insert our architecture definition.\n",
        "\n",
        "**5. How do you create a neural network using TensorFlow 2.0?**\n",
        "Ans.\n",
        "Implementation of a TensorFlow neural network.\n",
        "Step 1: Importing necessary libraries. ...\n",
        "Step 2: Downloading and preparing the dataset. ...\n",
        "Step 3: Verifying and visualizing the data. ...\n",
        "Step 4: Adding convolutional layers. ...\n",
        "Step 5: Adding neural network layers on top. ...\n",
        "Step 6: Training the model.\n",
        "\n",
        "**6. What is the importance of Tensor Space in TensorFlow?**\n",
        "Ans. Tensors are multi-dimensional arrays with a uniform type (called a dtype). You can see all supported dtypes at tf.dtypes.\n",
        "\n",
        "If you're familiar with NumPy, tensors are (kind of) like np.arrays.\n",
        "\n",
        "All tensors are immutable like Python numbers and strings: you can never update the contents of a tensor, only create a new one.\n",
        "\n",
        "**7. How can TensorBoard be integrated with TensorFlow 2.0?**\n",
        "Ans.\n",
        "Start by installing TF 2.0 and loading the TensorBoard notebook extension: For Jupyter users: If you've installed Jupyter and TensorBoard into the same virtualenv, then you should be good to go.\n",
        "\n",
        "**8.  What is the purpose of TensorFlow Playground?**\n",
        "Ans. Google's TensorFlow Playground is an interactive visualisation of neural networks. With it, you can simulate small neural networks in real-time in your browser, and see the results instantly.\n",
        "\n",
        "**9.  What is Neuron, and how is it useful for deep learning models?**\n",
        "Ans.\n",
        "Neurons in deep learning models are nodes through which data and computations flow. Neurons work like this: They receive one or more input signals. These input signals can come from either the raw data set or from neurons positioned at a previous layer of the neural net. They perform some calculations.\n",
        "\n",
        "**10.  What is the difference between TensorFlow and PyTorch?**\n",
        "Ans. PyTorch optimizes performance by taking advantage of native support for asynchronous execution from Python. In TensorFlow, you'll have to manually code and fine tune every operation to be run on a specific device to allow distributed training.\n",
        "\n",
        "**11.  How do you install PyTorch?**\n",
        "Ans.\n",
        "PyTorch Installation\n",
        "Install Python: sudo apt install python3.10. ...\n",
        "Create a virtual environment for Python: python3 -m venv venv.\n",
        "Activate the virtual environment: source venv/bin/activate. ...\n",
        "Install PyTorch libraries in the virtual environment: ...\n",
        "Verify PyTorch installation: ...\n",
        "Verify if PyTorch libraries use CUDA:\n",
        "\n",
        "**12.  What is the basic structure of a PyTorch neural network?**\n",
        "Ans.Every module in PyTorch subclasses the nn.Module. A neural network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex architectures easily.\n",
        "\n",
        "**13. What is the significance of tensors in PyTorch?**\n",
        "Ans.\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model's parameters.\n",
        "\n",
        "**14.  What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?**\n",
        "Ans. So generally both torch.Tensor and torch.cuda.Tensor are equivalent. You can do everything you like with them both.\n",
        "\n",
        "The key difference is just that torch.Tensor occupies CPU memory while torch.cuda.Tensor occupies GPU memory. Of course operations on a CPU Tensor are computed with CPU while operations for the GPU / CUDA Tensor are computed on GPU.\n",
        "\n",
        "**15.  What is the purpose of the torch.optim module in PyTorch?**\n",
        "Ans. torch.optim is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can also be easily integrated in the future.\n",
        "\n",
        "**16.  What are some common activation functions used in neural networks?**\n",
        "Sigmoid or Logistic Activation Function. The Sigmoid Function curve looks like a S-shape. ...\n",
        "Tanh or hyperbolic tangent Activation Function. tanh is also like logistic sigmoid but better. ...\n",
        "ReLU (Rectified Linear Unit) Activation Function. The ReLU is the most used activation function in the world right now. ...\n",
        "Leaky ReLU.\n",
        "\n",
        "**17.  What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?**\n",
        "\n",
        "Ans.  The difference between torch.nn.Module and torch.nn.Sequential in PyTorch.\n",
        "\n",
        "**torch.nn.Module:**\n",
        "\n",
        "Base Class: torch.nn.Module is the base class for all neural network modules in PyTorch. It provides the basic functionalities for defining and managing model parameters, defining the forward pass, and moving the model to different devices.\n",
        "Flexibility: It gives you complete flexibility to define custom architectures and complex operations within the forward method. You can use control flow, loops, and arbitrary computations to define how the input is processed.\n",
        "Usage: You would typically subclass torch.nn.Module when building custom models or when your model logic goes beyond simple sequential layer stacking.\n",
        "\n",
        "**torch.nn.Sequential:**\n",
        "\n",
        "Container: torch.nn.Sequential is a container that allows you to define a sequential stack of layers. It simplifies the model definition when the layers are applied in a straightforward order.\n",
        "Simplicity: It's convenient for creating simple linear sequences of operations, making the code more concise and readable.\n",
        "Usage: You can use torch.nn.Sequential when your model consists of a series of layers applied one after another.\n",
        "\n",
        "\n",
        "**18.  How can you monitor training progress in TensorFlow 2.0?**\n",
        "\n",
        "**Methods for Monitoring Training Progress**\n",
        "\n",
        "\n",
        "**Keras Callbacks:** Keras provides a powerful mechanism called callbacks that allow you to execute custom functions during training. You can use callbacks to:\n",
        "\n",
        "Print metrics: Display loss, accuracy, or other metrics at the end of each epoch or batch using tf.keras.callbacks.Callback.\n",
        "Log to TensorBoard: Visualize training progress, metrics, and model graphs using tf.keras.callbacks.TensorBoard.\n",
        "Early stopping: Stop training early if the model's performance on a validation set stops improving using tf.keras.callbacks.EarlyStopping.\n",
        "Model checkpointing: Save the model's weights at specific intervals or when the performance improves using tf.keras.callbacks.ModelCheckpoint.\n",
        "Custom callbacks: Define your own functions to perform specific actions during training.\n",
        "\n",
        "**19. How does the Keras API fit into TensorFlow 2.0?**\n",
        "\n",
        "In TensorFlow 2.0, Keras is the primary high-level API for building and training models. It's tightly integrated with TensorFlow and provides a user-friendly and intuitive interface for deep learning.\n",
        "\n",
        "**20.  What is an example of a deep learning project that can be implemented using TensorFlow 2.0?**\n",
        "\n",
        "Image Classification with the CIFAR-10 Dataset\n",
        "\n",
        "\n",
        "**21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?**\n",
        "\n",
        "The main advantage of using pre-trained models is the ability to leverage transfer learning. Transfer learning allows you to utilize the knowledge gained by a model trained on a large dataset for a different but related task.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ug-9Ocrzojo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical"
      ],
      "metadata": {
        "id": "QkOkcZGJ68w-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. How do you install and verify that TensorFlow 2.0 was installed successfully?**"
      ],
      "metadata": {
        "id": "3Ni90Fj58IgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow: Use pip to install TensorFlow 2.0:\n",
        "pip install tensorflow==2.0\n",
        "\n",
        "# Check Version: Print the TensorFlow version:\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "dF9EskRo8O4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.  How can you define a simple function in TensorFlow 2.0 to perform addition?**"
      ],
      "metadata": {
        "id": "unLlTEWl8vUq"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.function\n",
        "def add(a, b):\n",
        "  \"\"\"Adds two tensors.\n",
        "\n",
        "  Args:\n",
        "    a: A tensor.\n",
        "    b: Another tensor.\n",
        "\n",
        "  Returns:\n",
        "    The sum of the two tensors.\n",
        "  \"\"\"\n",
        "  return a + b\n",
        "\n",
        "# Example usage\n",
        "a = tf.constant(2)\n",
        "b = tf.constant(3)\n",
        "result = add(a, b)\n",
        "\n",
        "# To see the output, run the code."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2WIJQ8sp835A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?**"
      ],
      "metadata": {
        "id": "8YlwDlBF9Fgf"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)), # Hidden layer\n",
        "  tf.keras.layers.Dense(10, activation='softmax') # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WVCwPAC39Pqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.  How can you visualize the training progress using TensorFlow and Matplotlib?**"
      ],
      "metadata": {
        "id": "X6njtAXY9Rmx"
      }
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (define and compile your model as before) ...\n",
        "\n",
        "# Train the model and store history\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5-lcN51I9dus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How do you install PyTorch and verify the PyTorch installation?**"
      ],
      "metadata": {
        "id": "2PgLd0jQ9efX"
      }
    },
    {
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5A9YhAwZ9tg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "print(torch.__version__)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "i7Zk7lsk92bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **6. How do you create a simple neural network in PyTorch?**"
      ],
      "metadata": {
        "id": "c8sLtufe943d"
      }
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WzClTxUq-D1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.  How do you define a loss function and optimizer in PyTorch?**"
      ],
      "metadata": {
        "id": "kj1P-sD7-Fdj"
      }
    },
    {
      "source": [
        "criterion = nn.CrossEntropyLoss()  # Example: Cross-Entropy Loss"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6pSTyRKZ-RiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Example: Adam optimizer"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "edx5OMo_-Syb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.  How do you implement a custom loss function in PyTorch?**"
      ],
      "metadata": {
        "id": "wduNdMh3-V93"
      }
    },
    {
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyCustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Calculate the loss\n",
        "        loss = torch.mean((predictions - targets)**2)  # Example: Mean Squared Error\n",
        "        return loss\n",
        "\n",
        "# Create an instance of the custom loss function\n",
        "criterion = MyCustomLoss()\n",
        "\n",
        "# ... (use criterion in your training loop) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "hz-6tWan-iNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.  How do you save and load a TensorFlow model?**"
      ],
      "metadata": {
        "id": "0-WvlmqL-i5D"
      }
    },
    {
      "source": [
        "model.save('my_model.h5')  # Saves in HDF5 format\n",
        "   # Or:\n",
        "   model.save('my_model')  # Saves in SavedModel format"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7ifkYBHf-x80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "loaded_model = tf.keras.models.load_model('my_model.h5')\n",
        "   # Or:\n",
        "   loaded_model = tf.keras.models.load_model('my_model')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "bo79-Hpa-zW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}